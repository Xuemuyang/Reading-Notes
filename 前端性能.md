# 前端性能

## 初探

> 任何一个用户端的产品，都要把这六个过程滴水不漏的考虑到自己的性能优化方案内，反复权衡，从而打磨出用户满意的速度。

1. DNS 解析
1. TCP 连接
1. HTTP 请求抛出
1. 服务端处理请求
1. HTTP 响应返回
1. 浏览器拿到响应数据，解析响应内容，把解析的结果展示给用户

![思维导图](./images/performance/index.png)

## 网络优化

### Webpack性能调优与Gzip原理

前端在DNS与TCP这一层的努力非常有限，HTTP层的优化才是核心。

HTTP优化两个大方向：

- 减少请求次数
- 减少单次请求所花费的时间

#### Webpack

Webpack的优化瓶颈在两个方面：

- 构建时间
- 打包体积

1.不要让loader做太多事情

使用include或者exclude避免不必要的转译，还可以开启缓存，将转译结果缓存至文件系统。

2.第三方库的打包可以使用DLL

```js
const path = require('path')
const webpack = require('webpack')

module.exports = {
  entry: {
    // 依赖的库数组
    vendor: [
    'prop-types',
    'babel-polyfill',
    'react',
    'react-dom',
    'react-router-dom',
    ]
  },
  output: {
    path: path.join(__dirname, 'dist'),
    filename: '[name].js',
    library: '[name]_[hash]',
  },
  plugins: [
    new webpack.DllPlugin({
    // DllPlugin的name属性需要和libary保持一致
    name: '[name]_[hash]',
    path: path.join(__dirname, 'dist', '[name]-manifest.json'),
    // context需要和webpack.config.js保持一致
    context: __dirname,
    }),
  ],
}...
```

3.happypack多进程

4.删除冗余代码

webpack基于ES6的模块系统Tree-Shaking

在Uglify的操作中可以传入很多选项

```js
const UglifyJsPlugin = require('uglifyjs-webpack-plugin');
  module.exports = {
    plugins: [
      new UglifyJsPlugin({
        // 允许并发
        parallel: true,
        // 开启缓存
        cache: true,
        compress: {
          // 删除所有的console语句
          drop_console: true,
          // 把使用多次的静态值自动定义为变量
          reduce_vars: true,
        },
        output: {
          // 不保留注释
          comment: false,
          // 使输出的代码尽可能紧凑
          beautify: false
        }
      })
    ]
  }...
```

#### Gzip

Gzip的内核是Deflate。

压缩原理的背后是在文本文件中找出一些重复出现的字符串，临时替换他们，从而使整个文件变小。根据这个原理，文本中代码的重复率越高，压缩的效率就越高，Gzip的收益也越大。

Webpack中Gzip压缩操作的存在，事实上是为了在构建过程中做掉一部分服务器的工作，为服务器分压。

### 图片优化-质量与性能的博弈

与其说在“优化”，不如说是在做“权衡”，我们的主要任务就是去寻求一个质量与性能之间的平衡点。

#### 不同业务场景下的图片方案选型

在计算机中，像素用二进制数来表示，一个像素对应的二进制位数越多，可以表示的颜色种类就越多，成像效果越细腻，文件体积就越大。

一个二进制位表示两种颜色(0|1 对应 黑|白)，如果一个图片格式对应的二进制位有n个，那么它就可以呈现2^n种颜色。

##### JPEG/JPG

JPG的特点是有损压缩，当把体积压缩至原有体积的50%一下，任然可以保持住60%的品质。

JPG适用于呈现色彩吩咐的图片，JPG常用作大的背景图、轮播图或Banner图出现。

缺陷在于处理矢量图形和Logo等线条感较强、颜色对比强烈的图像时，认为压缩导致的图片模糊比较明显，且不支持透明。

##### PNG-8和PNG-24

8和24这里都是二进制位数，8位PNG支持256种颜色,24位的可以呈现约1600万种颜色。

考虑到PNG在处理线条和颜色对比度方面的优势，主要用来呈现小的Logo、颜色简单且对比强烈的图片或背景等。

比如某宝的Logo，较小的Logo(CSS Sprites)，颜色对比度较强的图片。

##### SVG

SVG文件体积小，压缩性强，图片可以无限放大且不失真。

##### Base64

base64作为CSS Sprites的补充而存在。

Base64编码后，图片大小会膨胀为源文件的4/3。

这是几条适用场景

- 图片的实际尺寸很小(大多不足2kb)
- 图片无法以sprites图片的形式与其它小图结合(sprites图片仍是主要的减少HTTP请求的途径，Base64是sprites的补充)
- 图片的更新频率非常低(不需要我们重复编码和修改文件内容，维护成本较低)

推荐使用webpack的url-loader进行Base64编码。

##### WebP

什么都好除了兼容性

```html
<img src="//img.alicdn.com/tps/i4/TB1CKSgIpXXXXccXXXX07tlTXXX-200-200.png_60x60.jpg_.webp" alt="手机app - 聚划算" class="app-icon">
```

在wdbp前面还有一个jpg的后缀，这里是降级方案。

##### 小结

做电商就是做图片...

## 浏览器缓存机制与缓存策略

浏览器缓存机制

- Memory Cache
- Service Worker Cache
- HTTP Cache
- Push Cache(HTTP2新特性)

### HTTP缓存机制

强缓存和协商缓存，命中强缓存失败的情况下，才会走协商缓存。

强缓存中的expires的问题在于对“本地时间”的依赖。

Cache-Control可以视作是expires的完全替代方案。

当下使用expires的唯一目的就是向下兼容。

Cache-Control 相对于 expires 更加准确，它的优先级也更高。当 Cache-Control 与 expires 同时出现时，以 Cache-Control 为准。

Cache-Control不止是`max-age`。

```HTTP header
cache-control: max-age=3600, s-maxage=31536000
```

`s-maxage`用来表示cache服务器(比如cache CDN)的缓存有效时间，并且只对`public`有效。

`public`和`private`是针对资源是否能够被代理服务器缓存而存在的一组对立概念，`private`是默认值。

`no-cache`绕开了浏览器，设置了`no-cache`之后，每一次请求都不会再去询问浏览器的缓存情况，而是直接向服务端去确认该资源是否过期。

`no-store`不使用任何缓存，直接向服务端发送请求，下载完整响应。

`Last-Modified`存在一些缺陷，比如修改文件速度过快(小于1s)，编辑了文件，但文件内容没有变化。于是有了`Etag`作为`Last-Modified`的补充。`Etag`的生成过程需要服务器额外付出开销，影响服务端的性能，这是它的弊端，是否启用`Etag`需要考量。`Etag`并不能替代`Last-Modified`，只作为`Last-Modified`的补充和强化。

`Etag`的优先级更高，当和`Last-Modified`同时存在时，以`Etag`为准。

![缓存的选择](./images/performance/cache-choice.png)

Service Worker对协议有要求，必须以https协议为前提。

## 本地存储---从cookie到Web Storage、IndexDB

cookie以key-value的形式存在。

cookie的体积有上限，最大4kb。

cookie紧跟域名。

```http header
Set-Cookie: name=xiuyan; domain=xiuyan.me
```

同一个域名下的所有请求，都会携带cookie。cookie虽然小，请求可以有很多，随着请求的叠加，不必要的cookie带来的开销将是无法想象的。

Local Storage、Session Storage和Cookie都遵循同源策略。

Web Storage只能存储字符串。

IndexDB是一个运行在浏览器上的非关系型数据库。

当数据的复杂度和规模上升到了Local Storage无法解决的程度，可以使用IndexDB。

## CDN的缓存和回源机制解析

CDN （内容分发网络）指的是一组分布在各个地区的服务器。这些服务器存储着数据的副本，因此服务器可以根据哪些服务器与用户距离最近，来满足数据的请求。 CDN 提供快速服务，较少受高流量影响。

CDN两个核心功能

- 缓存 把资源copy到CDN服务器上
- 回源 CDN发现自己没有这个资源，向服务器请求这个资源

CDN往往被用来存放静态资源。

业务服务器的核心人物在于生成动态页面或返回非纯静态页面，这两种过程是需要计算的。

“静态资源”是像js、css、图片等不需要业务服务器进行计算即可得到的资源。

许多一线公司，静态资源走CDN并不是一个建议，而是规定。

## 服务端渲染的探索和实践

```js
const Vue = require('vue')
// 创建一个express应用
const server = require('express')()
// 提取出renderer实例
const renderer = require('vue-server-renderer').createRenderer()

server.get('*', (req, res) => {
  // 编写Vue实例（虚拟DOM节点）
  const app = new Vue({
    data: {
      url: req.url
    },
    // 编写模板HTML的内容
    template: `<div>访问的 URL 是： {{ url }}</div>`
  })

  // renderToString 是把Vue实例转化为真实DOM的关键方法
  renderer.renderToString(app, (err, html) => {
    if (err) {
      res.status(500).end('Internal Server Error')
      return
    }
    // 把渲染出来的真实DOM字符串插入HTML模板中
    res.end(`
      <!DOCTYPE html>
      <html lang="en">
        <head><title>Hello</title></head>
        <body>${html}</body>
      </html>
    `)
  })
})

server.listen(8080)
```

把Vue、React等在Node上跑一遍，`renderToString`，将结果插入HTML模板中，将虚拟DOM转化为真实DOM。

## 浏览器背后的运行机制

浏览器内核分为两部分

- 渲染引擎(layout engineer)
- JS引擎(rendering engineer)

常见的渲染引擎

- Trident(IE)
- Gecko(FireFox)
- Blink(Chrome、Opera)
- Webkit(Safari)

Blink是Webkit衍生而来的一个分支。

CSS选择器从右往左匹配，可以有如下优化方案：

- 避免使用通配符
- 关注可以通过继承实现的属性，避免重复匹配重复定义
- 少用标签选择器
- 减少嵌套

CSSOM的解析过程与DOM的解析过程是并行的。

默认情况下，CSS是阻塞的资源，在浏览器构建CSSOM的过程中，不会渲染任何已处理的内容，即便DOM已经解析完了（避免没有CSS的HTML呈现在用户眼前）。

> CSS是阻塞渲染的资源，需要将它尽早。尽快地下载到客户端，以便缩短首次渲染时间。

JS引擎独立与渲染引擎存在，JS代码在何处插入，就在何处执行。

JS的三种加载方式

- 正常模式
- async 加载是异步的，当加载结束，立即执行
- defer 加载异步，执行被推迟，当文档解析完成，DOMContentLoaded事件即将被触发，defer才会依次执行。

## DOM优化原理与基本实践